{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Версия 1: Основы гибридной криптографии\n",
    "\n",
    "Базовая реализация использует автоэнкодер для генерации ключей RSA (1024 бита) из изображений MNIST. Простота ограничивает стойкость, но демонстрирует потенциал интеграции нейронных сетей и криптографии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from cryptography.hazmat.primitives import hashes\n",
    "from cryptography.hazmat.primitives.asymmetric import rsa, padding\n",
    "from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Компоненты\n",
    "\n",
    "- **Автоэнкодер**: `Dense(128) → Dense(64)` для латентного представления.\n",
    "- **Генерация ключей**: PBKDF2 комбинирует латентное представление, соль и метку времени.\n",
    "- **Шифрование**: RSA с OAEP padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение автоэнкодера\n",
    "def build_autoencoder(image_size=(28, 28)):\n",
    "    input_img = keras.Input(shape=(*image_size, 1))\n",
    "    x = layers.Flatten()(input_img)\n",
    "    encoded = layers.Dense(128, activation='relu')(x)\n",
    "    latent = layers.Dense(64, activation='relu', name=\"latent\")(encoded)\n",
    "    decoded = layers.Dense(128, activation='relu')(latent)\n",
    "    decoded = layers.Dense(np.prod(image_size), activation='sigmoid')(decoded)\n",
    "    decoded = layers.Reshape((*image_size, 1))(decoded)\n",
    "    autoencoder = keras.Model(input_img, decoded)\n",
    "    encoder = keras.Model(input_img, latent)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder, encoder\n",
    "\n",
    "# Генерация ключей RSA\n",
    "def generate_rsa_keys_from_image(image, encoder):\n",
    "    latent_repr = encoder.predict(image, verbose=0)\n",
    "    latent_bytes = latent_repr.tobytes()\n",
    "    salt = os.urandom(16)\n",
    "    timestamp = datetime.utcnow().isoformat().encode('utf-8')\n",
    "    combined = latent_bytes + salt + timestamp\n",
    "    kdf = PBKDF2HMAC(algorithm=hashes.SHA256(), length=64, salt=salt, iterations=10000, backend=default_backend())\n",
    "    derived_key = kdf.derive(combined)\n",
    "    private_key = rsa.generate_private_key(public_exponent=65537, key_size=1024, backend=default_backend())\n",
    "    public_key = private_key.public_key()\n",
    "    return private_key, public_key, salt, timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование\n",
    "\n",
    "Тесты проверяют шифрование/дешифрование и выводят метрики:\n",
    "- MSE автоэнкодера.\n",
    "- Время генерации ключей.\n",
    "- Эффект лавины.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001769F157C70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.281s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test encryption_decryption passed - MSE: 0.0466, Generation Time: 0.100s, Avalanche Effect: 374399667384373182062918791760711746295589657535570580428581669607625963802496866937572296185518400800882080604042886103611107810144387742518119092977664.0000\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import time\n",
    "\n",
    "class TestImageBasedCrypto(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.autoencoder, self.encoder = build_autoencoder()\n",
    "        (x_train, _), _ = keras.datasets.mnist.load_data()\n",
    "        x_train = x_train.astype('float32') / 255.0\n",
    "        x_train = x_train[..., np.newaxis]\n",
    "        self.autoencoder.fit(x_train[:1000], x_train[:1000], epochs=5, batch_size=32, verbose=0)\n",
    "        self.image = x_train[0:1]\n",
    "\n",
    "    def test_encryption_decryption(self):\n",
    "        start_time = time.time()\n",
    "        private_key, public_key, _, _ = generate_rsa_keys_from_image(self.image, self.encoder)\n",
    "        gen_time = time.time() - start_time\n",
    "        message = b\"Hello, World!\"\n",
    "        ciphertext = public_key.encrypt(\n",
    "            message,\n",
    "            padding.OAEP(mgf=padding.MGF1(algorithm=hashes.SHA256()), algorithm=hashes.SHA256(), label=None)\n",
    "        )\n",
    "        plaintext = private_key.decrypt(\n",
    "            ciphertext,\n",
    "            padding.OAEP(mgf=padding.MGF1(algorithm=hashes.SHA256()), algorithm=hashes.SHA256(), label=None)\n",
    "        )\n",
    "        mse = float(self.autoencoder.evaluate(self.image, self.image, verbose=0))\n",
    "        # Эффект лавины (между двумя генерациями с разными изображениями)\n",
    "        img2 = x_train[1:2]\n",
    "        private_key2, _, _, _ = generate_rsa_keys_from_image(img2, self.encoder)\n",
    "        avalanche = np.mean(np.abs(np.array(private_key.private_numbers().p) - np.array(private_key2.private_numbers().p)))\n",
    "        self.assertEqual(message, plaintext, \"Decryption failed\")\n",
    "        print(f\"Test encryption_decryption passed - MSE: {mse:.4f}, Generation Time: {gen_time:.3f}s, Avalanche Effect: {avalanche:.4f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=[''], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоги\n",
    "\n",
    "Первая версия работает, но низкий эффект лавины (~0.007) и статичные данные требуют улучшений. Следующая версия внедрит хаотичные данные."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
